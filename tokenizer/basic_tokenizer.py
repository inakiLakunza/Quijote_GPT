


class BasicTokenizer:

    """
    Implementation of a simple Tokenizer, which will be used for training
    it on a chosen text and then visualize the merged tokens.
    """

    def __init__(self, text, vocab_size, verbose=False):
        pass

    def encode(self, text):
        pass

    def decode(self, ids):
        pass